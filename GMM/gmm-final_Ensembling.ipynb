{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6757bac9",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-21T11:35:36.192640Z",
     "iopub.status.busy": "2024-03-21T11:35:36.192110Z",
     "iopub.status.idle": "2024-03-21T11:35:40.763508Z",
     "shell.execute_reply": "2024-03-21T11:35:40.762564Z"
    },
    "papermill": {
     "duration": 4.582156,
     "end_time": "2024-03-21T11:35:40.766064",
     "exception": false,
     "start_time": "2024-03-21T11:35:36.183908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-2.12.1.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from os.path import isdir, join\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import plotly.express as px\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# Math\n",
    "import numpy as np\n",
    "from scipy.fftpack import fft\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "import pickle\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import IPython.display as ipd\n",
    "import librosa.display\n",
    "\n",
    "import plotly.offline as py\n",
    "py.init_notebook_mode(connected=True)\n",
    "import plotly.graph_objs as go\n",
    "import plotly.tools as tls\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b3db8c",
   "metadata": {
    "papermill": {
     "duration": 0.005912,
     "end_time": "2024-03-21T11:35:40.778600",
     "exception": false,
     "start_time": "2024-03-21T11:35:40.772688",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Record Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dba63856",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T11:35:57.247134Z",
     "iopub.status.busy": "2024-03-21T11:35:57.246709Z",
     "iopub.status.idle": "2024-03-21T11:35:57.256524Z",
     "shell.execute_reply": "2024-03-21T11:35:57.255270Z"
    },
    "papermill": {
     "duration": 0.020819,
     "end_time": "2024-03-21T11:35:57.258945",
     "exception": false,
     "start_time": "2024-03-21T11:35:57.238126",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_extractor(sound_path, win_length_ms=25, hop_length_ms=10):\n",
    "    # Load the audio file\n",
    "    signal, sr = librosa.load(sound_path,sr=8000)\n",
    "    # signal,sr = wavfile.read(sound_path)\n",
    "    # Extract MFCCs\n",
    "    win_length_samples = int(sr * win_length_ms / 1000)\n",
    "    hop_length_samples = int(sr * hop_length_ms / 1000)\n",
    "    mfccs = librosa.feature.mfcc(y=signal, sr=sr, n_mfcc=13, hop_length=hop_length_samples, win_length=win_length_samples)\n",
    "    # mfccs = mfcc(signal,samplerate=sr,nfft = 2048,numcep=13,nfilt=13)\n",
    "    \n",
    "    #Extract first MFCCs derivatives\n",
    "    delta_mfccs = librosa.feature.delta(mfccs)\n",
    "    \n",
    "    # Extract second MFCCs derivatives\n",
    "    delta2_mfccs = librosa.feature.delta(mfccs, order=2)\n",
    "    \n",
    "    # # Concatenate features\n",
    "    mfccs_features = np.concatenate((mfccs, delta_mfccs, delta2_mfccs))\n",
    "    \n",
    "    # Return all features\n",
    "    return mfccs, delta_mfccs, delta2_mfccs, mfccs_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "11d83e5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T11:35:57.274922Z",
     "iopub.status.busy": "2024-03-21T11:35:57.274488Z",
     "iopub.status.idle": "2024-03-21T11:35:57.285185Z",
     "shell.execute_reply": "2024-03-21T11:35:57.283916Z"
    },
    "papermill": {
     "duration": 0.02169,
     "end_time": "2024-03-21T11:35:57.287728",
     "exception": false,
     "start_time": "2024-03-21T11:35:57.266038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess(path, is_pca=0, num_pca = 2, window_length_ms=20, hop_length_ms=10):\n",
    "    '''\n",
    "    Return the numpy array\n",
    "    '''\n",
    "    # Get the path of the audio file\n",
    "    audio_file = Path(path)\n",
    "    samples,sample_rate = librosa.load(audio_file,sr=8000)\n",
    "    # print(f\"The original samples are {samples.shape} and sample rate is {sample_rate}\")\n",
    "    # Remove silence at start and end\n",
    "    # TODO: Apply VAD\n",
    "    # samples_trimmed, _= librosa.effects.trim(samples, top_db=60)\n",
    "    a, b, c, d = feature_extractor(audio_file,window_length_ms,hop_length_ms)\n",
    "    # tot= np.concatenate((a,b,c,d)).T\n",
    "    tot = d.T\n",
    "          \n",
    "    # Create a DataFrame with column names as MFCC_1, MFCC_2, etc.\n",
    "    columns = [f'MFCC_{i+1}' for i in range(tot.shape[1])]\n",
    "    df = pd.DataFrame(tot, columns=columns)\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    #csv_filename = '{path}.csv'\n",
    "    #df.to_csv(csv_filename, index=False)\n",
    "    \n",
    "    if(is_pca==1):\n",
    "        pca = PCA(n_components=num_pca)\n",
    "        components = pca.fit_transform(df)\n",
    "        df = pd.DataFrame(data=components)\n",
    "    df_new = df.to_numpy()\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5b994032",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T11:35:57.304369Z",
     "iopub.status.busy": "2024-03-21T11:35:57.303979Z",
     "iopub.status.idle": "2024-03-21T11:35:57.314674Z",
     "shell.execute_reply": "2024-03-21T11:35:57.313448Z"
    },
    "papermill": {
     "duration": 0.02329,
     "end_time": "2024-03-21T11:35:57.318113",
     "exception": false,
     "start_time": "2024-03-21T11:35:57.294823",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_folder(folder_path, is_pca=0, num_pca=2, items=50,window_length_ms=20, hop_length_ms=10):\n",
    "    '''\n",
    "    Return a numpy array containing preprocessed data from all .wav files in the specified folder.\n",
    "    '''\n",
    "    # Initialize an empty list to store data from all files\n",
    "    data_list = []\n",
    "    i = 0\n",
    "    # Iterate over all files in the folder\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if(i>items):\n",
    "            break\n",
    "        # Check if the file is a .wav file\n",
    "        if file_name.endswith('.wav'):\n",
    "            # Get the full path of the audio file\n",
    "            audio_file = os.path.join(folder_path, file_name)\n",
    "            # samples, sample_rate = librosa.load(audio_file, sr=16000)\n",
    "            #print(f\"Processing {audio_file}: original samples are {samples.shape} and sample rate is {sample_rate}\")\n",
    "\n",
    "            # Remove silence at start and end\n",
    "            # samples_trimmed, _ = librosa.effects.trim(samples, top_db=60)\n",
    "            a, b, c, d = feature_extractor(audio_file)\n",
    "            # tot = np.concatenate((a, b, c, d)).T\n",
    "            tot = d.T\n",
    "\n",
    "            # Create a DataFrame with column names as MFCC_1, MFCC_2, etc.\n",
    "            columns = [f'MFCC_{i+1}' for i in range(tot.shape[1])]\n",
    "            df = pd.DataFrame(tot, columns=columns)\n",
    "\n",
    "            if is_pca == 1:\n",
    "                pca = PCA(n_components=num_pca)\n",
    "                components = pca.fit_transform(df)\n",
    "                df = pd.DataFrame(data=components)\n",
    "\n",
    "            # Append the DataFrame to the list\n",
    "            data_list.append(df)\n",
    "        i += 1\n",
    "\n",
    "    # Concatenate all DataFrames in the list to create a single DataFrame\n",
    "    concatenated_df = pd.concat(data_list, ignore_index=True)\n",
    "    \n",
    "    # Convert the DataFrame to a numpy array\n",
    "    array_data = concatenated_df.to_numpy()\n",
    "    \n",
    "    return array_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23a49c00",
   "metadata": {
    "papermill": {
     "duration": 0.006933,
     "end_time": "2024-03-21T11:35:57.348038",
     "exception": false,
     "start_time": "2024-03-21T11:35:57.341105",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Main Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b27957fb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T11:35:57.391593Z",
     "iopub.status.busy": "2024-03-21T11:35:57.390812Z",
     "iopub.status.idle": "2024-03-21T11:35:57.395970Z",
     "shell.execute_reply": "2024-03-21T11:35:57.394783Z"
    },
    "papermill": {
     "duration": 0.017181,
     "end_time": "2024-03-21T11:35:57.398274",
     "exception": false,
     "start_time": "2024-03-21T11:35:57.381093",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_paths = [\"../Dataset/Language-Recognition-VADaudio/Gujrati-Train\", \"../Dataset/Language-Recognition-VADaudio/Tamil-Train\",\"../Dataset/Language-Recognition-VADaudio/Telugu-Train\"]\n",
    "test_paths = [\"../Dataset/Language-Recognition-VADaudio/Gujrati-Test\",\"../Dataset/Language-Recognition-VADaudio/Tamil-Test\",\"../Dataset/Language-Recognition-VADaudio/Telugu-Test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "024ae858",
   "metadata": {},
   "outputs": [],
   "source": [
    "\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9d4c4114",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GMMModelEnsemble:\n",
    "    def __init__(self, base_path, start_name, accuracy, f1score):\n",
    "        self.models = []\n",
    "        self.base_path = base_path\n",
    "        self.start_name = start_name\n",
    "        self.accuracy = accuracy\n",
    "        self.f1score = f1score\n",
    "        self.load_models()\n",
    "\n",
    "    def load_models(self):\n",
    "        folder_path = self.base_path\n",
    "        for filename in os.listdir(folder_path):\n",
    "            if filename.startswith(self.start_name) and filename.endswith(\".pkl\"):\n",
    "                model_path = os.path.join(folder_path, filename)\n",
    "                with open(model_path, 'rb') as f:\n",
    "                    model = pickle.load(f)\n",
    "                parts = filename.split(\"_\")\n",
    "                num_pca = int(parts[-2])  # Corrected calculation of num_pca\n",
    "                language = int(parts[-1].split(\".\")[0])  # Extract language from filename\n",
    "                acc = self.accuracy[language - 1]  # Language is used to index accuracy array\n",
    "                f1 = self.f1score[language - 1]  # Language is used to index f1score array\n",
    "                print(filename, num_pca, acc, f1, language)\n",
    "                self.models.append({'model': model, 'num_pca': num_pca, 'accuracy': acc, 'f1score': f1})\n",
    "        \n",
    "        print(len(self.models))\n",
    "\n",
    "    def ensembled_vote(self, vector,acc_or_f1):\n",
    "        prediction = 0  # Initialize votes for each model\n",
    "        log_likelihoods = np.zeros(len(self.models))\n",
    "        for i, model_info in enumerate(self.models):\n",
    "            model = model_info['model']\n",
    "            num_pca = model_info['num_pca']\n",
    "            # print(vector)\n",
    "            # Preprocess the vector based on num_pca\n",
    "            processed_vector = preprocess(vector, is_pca=1, num_pca=num_pca)\n",
    "            log_likelihoods[i] = model.get_score(processed_vector)\n",
    "        predicted_class = np.argmax(log_likelihoods)\n",
    "        # print(log_likelihoods)\n",
    "        prediction = predicted_class # Vote for the predicted class\n",
    "        # print(np.argmax(log_likelihoods))\n",
    "        if acc_or_f1 == 'acc':\n",
    "            return prediction, self.accuracy[predicted_class]\n",
    "        return prediction , self.f1score[predicted_class]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8ca6ddc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gmmdiag_32_24_1.pkl 24 0 0 1\n",
      "gmmdiag_32_24_2.pkl 24 0.54 0.4137931034482759 2\n",
      "gmmdiag_32_24_3.pkl 24 0.87 0.763157894736842 3\n",
      "3\n",
      "gmmdiag_64_24_1.pkl 24 0.03 0.05084745762711864 1\n",
      "gmmdiag_64_24_2.pkl 24 0.56 0.42424242424242425 2\n",
      "gmmdiag_64_24_3.pkl 24 0.8 0.7339449541284404 3\n",
      "3\n",
      "gmmdiag_120_24_1.pkl 24 0.03 0.048 1\n",
      "gmmdiag_120_24_2.pkl 24 0.57 0.4115523465703971 2\n",
      "gmmdiag_120_24_3.pkl 24 0.65 0.6565656565656566 3\n",
      "3\n",
      "gmmdiag_256_24_1.pkl 24 0.0 0 1\n",
      "gmmdiag_256_24_2.pkl 24 0.54 0.4137931034482759 2\n",
      "gmmdiag_256_24_3.pkl 24 0.88 0.7652173913043478 3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Create 4 instances of GMMModelEnsemble and\n",
    "# load the models for each language\n",
    "base = r\"C:\\Users\\Rashaad Ali Baig\\CS361\\CS361-Course-Project\\GMM\\GMM-models\"\n",
    "\n",
    "Ensembled_gmms = [\n",
    "    GMMModelEnsemble(\n",
    "        base_path=os.path.join(base, \"32_64\", \"Models\"),\n",
    "        start_name=\"gmmdiag_32_24\",\n",
    "        accuracy=[0, 0.54, 0.87],\n",
    "        f1score=[0, 0.4137931034482759, 0.763157894736842]\n",
    "    ),\n",
    "    GMMModelEnsemble(\n",
    "        base_path=os.path.join(base, \"32_64\", \"Models\"),\n",
    "        start_name=\"gmmdiag_64_24\",\n",
    "        accuracy=[0.03, 0.56, 0.80],\n",
    "        f1score=[0.05084745762711864, 0.42424242424242425, 0.7339449541284404]\n",
    "    ),\n",
    "    GMMModelEnsemble(\n",
    "        base_path=os.path.join(base, \"120\", \"Models\"),\n",
    "        start_name=\"gmmdiag_120_24\",\n",
    "        accuracy=[0.03, 0.57, 0.65],\n",
    "        f1score=[0.048, 0.4115523465703971, 0.6565656565656566]\n",
    "    ),\n",
    "    GMMModelEnsemble(\n",
    "        base_path=os.path.join(base, \"256\", \"Models\"),\n",
    "        start_name=\"gmmdiag_256_24\",\n",
    "        accuracy=[0.0, 0.54, 0.88],\n",
    "        f1score=[0, 0.4137931034482759, 0.7652173913043478]\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d35f853",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = np.zeros((3, 3))  # 3 classes: Gujrati, Tamil, Telugu\n",
    "\n",
    "for idx, path in enumerate(test_paths):\n",
    "    # Initialize counters for each class\n",
    "    class_counts = {0: 0, 1: 0, 2: 0}\n",
    "    for root, _, files in os.walk(path):\n",
    "        for file in files:\n",
    "            vote = np.zeros(3)\n",
    "            for i in range(len(Ensembled_gmms)):\n",
    "                voteclass, weight = Ensembled_gmms[i].ensembled_vote(root+'/'+file, 'acc')\n",
    "            vote[voteclass] += weight\n",
    "            winner = np.argmax(vote)\n",
    "            class_counts[winner] += 1  # Increment the count for the winner class\n",
    "        print(path, )\n",
    "    # Update confusion matrix\n",
    "    for true_label, count in class_counts.items():\n",
    "        confusion_matrix[idx, true_label] = count\n",
    "\n",
    "    # Define class labels\n",
    "class_labels = ['Gujrati', 'Tamil', 'Telugu']\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g', xticklabels=class_labels, yticklabels=class_labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
    "print(f\"Overall Accuracy: {accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52e3e05",
   "metadata": {
    "papermill": {
     "duration": 0.016507,
     "end_time": "2024-03-21T19:20:00.541553",
     "exception": false,
     "start_time": "2024-03-21T19:20:00.525046",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e7439a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d0b2659",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T19:20:00.578100Z",
     "iopub.status.busy": "2024-03-21T19:20:00.577416Z",
     "iopub.status.idle": "2024-03-21T19:20:00.594113Z",
     "shell.execute_reply": "2024-03-21T19:20:00.592417Z"
    },
    "papermill": {
     "duration": 0.038864,
     "end_time": "2024-03-21T19:20:00.597332",
     "exception": false,
     "start_time": "2024-03-21T19:20:00.558468",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def pipeline_full(n_components_gmm,is_pca,num_pca):\n",
    "#     gmms = []\n",
    "\n",
    "#     for path in train_paths:\n",
    "#         X = preprocess_folder(path,is_pca,num_pca,items=240)\n",
    "#         gmm = GMMNew(n_components_gmm,100,'full')\n",
    "#         gmm.fit(data=X)\n",
    "#         gmms.append(gmm)\n",
    "#         with open(f'gmmfull_{n_components_gmm}_{num_pca}.pkl', 'wb') as f:\n",
    "#             pickle.dump(gmm, f)\n",
    "#         print(f\"{path} is done\")\n",
    "\n",
    "#     # Initialize confusion matrix\n",
    "#     confusion_matrix = np.zeros((3, 3))  # 3 classes: Gujrati, Tamil, Telugu\n",
    "\n",
    "#     for idx, path in enumerate(test_paths):\n",
    "#         # Initialize counters for each class\n",
    "#         class_counts = {0: 0, 1: 0, 2: 0}\n",
    "#         for root, _, files in os.walk(path):\n",
    "#             for file in files:\n",
    "#                 vector = preprocess(root+'/'+file,is_pca,num_pca)\n",
    "#                 log_likelihood = np.zeros(len(gmms)) \n",
    "#                 for i in range(len(gmms)):\n",
    "#                     gmm    = gmms[i]  #checking with each model one by one\n",
    "#                     log_likelihood[i] = gmm.get_score(vector)\n",
    "            \n",
    "#                 winner = np.argmax(log_likelihood)\n",
    "#                 class_counts[winner] += 1  # Increment the count for the winner class\n",
    "\n",
    "#         # Update confusion matrix\n",
    "#         for true_label, count in class_counts.items():\n",
    "#             confusion_matrix[idx, true_label] = count\n",
    "\n",
    "#     # Define class labels\n",
    "#     class_labels = ['Gujrati', 'Tamil', 'Telugu']\n",
    "\n",
    "#     plt.figure(figsize=(8, 6))\n",
    "#     sns.heatmap(confusion_matrix, annot=True, cmap='Blues', fmt='g', xticklabels=class_labels, yticklabels=class_labels)\n",
    "#     plt.xlabel('Predicted Label')\n",
    "#     plt.ylabel('True Label')\n",
    "#     plt.title('Confusion Matrix')\n",
    "#     plt.show()\n",
    "\n",
    "#     # Calculate accuracy\n",
    "#     accuracy = np.trace(confusion_matrix) / np.sum(confusion_matrix)\n",
    "#     print(f\"Overall Accuracy: {accuracy*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e03767a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-21T19:20:00.633132Z",
     "iopub.status.busy": "2024-03-21T19:20:00.632751Z",
     "iopub.status.idle": "2024-03-21T19:20:00.637746Z",
     "shell.execute_reply": "2024-03-21T19:20:00.636480Z"
    },
    "papermill": {
     "duration": 0.026027,
     "end_time": "2024-03-21T19:20:00.640292",
     "exception": false,
     "start_time": "2024-03-21T19:20:00.614265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# n_comp_list = [32,64,120,256,512]\n",
    "# num_pca_list = [39,24,13,6]\n",
    "# for num_pca_cand in num_pca_list:\n",
    "#     for n_comp in n_comp_list:\n",
    "#         print(f\"Num comp:{n_comp}, Num PCA:{num_pca_cand}\")\n",
    "#         if(num_pca_cand==39):\n",
    "#             is_pca = 0\n",
    "#         else:\n",
    "#             is_pca = 1\n",
    "#         pipeline(n_comp,is_pca,num_pca_cand)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4640507,
     "sourceId": 7901425,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4642876,
     "sourceId": 7904573,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30674,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 27869.093764,
   "end_time": "2024-03-21T19:20:02.049647",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-21T11:35:32.955883",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
